**Abstract**

In recent years, automatic colorization of line art has become a popular topic in machine learning. It is extremely useful in professional illustration production. The key point for improving this field is how to generate the correct color, user-controllable, saturated, and vivid colorization results. In previous works, there were significant improvements in solving color mistakes and color overflow problems. However, it is still desired to improve the quality of coloring in terms of color saturation and vividness. It can be easily distinguished whether the color image is generated by a machine learning model or is drawn by a human illustrator with human eyes. In this paper, we investigate improving color saturation and vividness.
According to the good color quality of StyleGAN's generating results. We use StyleGAN architecture as the basis. We modify the model architecture by adding conditional control, converting the lines and user hints into style, and then generating the colorization result of the line art through this style. Our method indeed inherits the outstanding color quality of StyleGAN. It has a better saturation and naturalness in colorization results and has a better FID score than previous works.
# 
**Line Art Colorization with our Model:**
# 
![](/guanweichen/projects/ai_game_art/line_art_colorization/colorization.png)
# 
**Compare to Previous Works:**
# 
![](/guanweichen/projects/ai_game_art/line_art_colorization/model_compare.png)
# 
**Reference Colorization with our Model:**
# 
![](/guanweichen/projects/ai_game_art/line_art_colorization/reference_colorization.png)